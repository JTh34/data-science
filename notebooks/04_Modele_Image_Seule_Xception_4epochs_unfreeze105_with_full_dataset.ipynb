{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0038290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 09:40:29.411916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, downloader\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import pad_sequences\n",
    "from tensorflow.keras.layers import Input, BatchNormalization,concatenate, Dense, Embedding, Flatten, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception,preprocess_input \n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "499d80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(\"../data/X_train_update.csv\", index_col='Unnamed: 0')\n",
    "target = pd.read_csv(\"../data/Y_train_CVw08PX.csv\", index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07453b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \n",
       "0                                                NaN  3804725264  1263597046  \n",
       "1                                                NaN   436067568  1008141237  \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978  \n",
       "3                                                NaN    50418756   457047496  \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b632ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "target_le = label_encoder.fit_transform(target['prdtypecode'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d1ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = all_data['designation']\n",
    "\n",
    "# tokenisationx\n",
    "tokens = [simple_preprocess(sent, min_len = 3) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d16a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille maximum des sequences de tokens : 33\n"
     ]
    }
   ],
   "source": [
    "# calcul de la longueur max des séquences de tokens\n",
    "size_tokens = map(lambda x:len(x),tokens)\n",
    "max_len = max(size_tokens)\n",
    "\n",
    "print(\"taille maximum des sequences de tokens :\", max_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10553401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de l'embedding préentrainé GLoVe dimension 100\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(\"../data/glove/glove.6B.100d.txt\")\n",
    "\n",
    "for line in f :\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coeffs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coeffs \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47eb4d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de phrases traitées : 84916\n",
      "nombre de mots traités : 696547\n"
     ]
    }
   ],
   "source": [
    "# création du dicitonnaire\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "\n",
    "print(\"nombre de phrases traitées :\", dictionary.num_docs)\n",
    "print(\"nombre de mots traités :\", dictionary.num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453efa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60867, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tri du dictionnaire par ordre de fréquence d'appartion décroissante des tokens\n",
    "sort_dictionary = sorted(dictionary.cfs.items(), key = lambda t : -t[1])\n",
    "words = [dictionary[t[0]] for t in sort_dictionary]\n",
    "\n",
    "# création de la matrice d'embedding de dimension 100 pour les \"max_words\" les plus fréquents\n",
    "embedding_dim = 100\n",
    "max_words = len(dictionary)+1 # on prend tout le dicitonnaire ici\n",
    "\n",
    "embedding_matrix = np.zeros((max_words,embedding_dim))\n",
    "\n",
    "for  i, word in enumerate(words) :\n",
    "    if i < max_words :\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    \n",
    "    if  embedding_vector is not None :\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28055ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84916, 33)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformation des tokens de chaque ligne en son identifiant unique dans le dicitonnaire\n",
    "tokens2id = [dictionary.doc2idx(t) for t in tokens]\n",
    "\n",
    "# padding des séquences d'ID pour qu'ils aient tous une taille de 33 (max_len)\n",
    "tokens2id_pad = pad_sequences(tokens2id , maxlen =  max_len, padding = 'post')\n",
    "\n",
    "tokens2id_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fa1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'un colone 'tokens2id' au df des données avant le spilt Train/Test/Valid/\n",
    "all_data['tokens2id'] = pd.Series(list(tokens2id_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5a8a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "      <th>productid</th>\n",
       "      <th>imageid</th>\n",
       "      <th>tokens2id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3804725264</td>\n",
       "      <td>1263597046</td>\n",
       "      <td>[3, 2, 6, 4, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436067568</td>\n",
       "      <td>1008141237</td>\n",
       "      <td>[19, 14, 9, 8, 28, 20, 25, 8, 10, 21, 18, 12, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
       "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
       "      <td>201115110</td>\n",
       "      <td>938777978</td>\n",
       "      <td>[33, 38, 31, 30, 32, 34, 39, 36, 35, 37, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50418756</td>\n",
       "      <td>457047496</td>\n",
       "      <td>[45, 42, 43, 40, 44, 41, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La Guerre Des Tuques</td>\n",
       "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
       "      <td>278535884</td>\n",
       "      <td>1077757786</td>\n",
       "      <td>[46, 14, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         designation  \\\n",
       "0  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
       "1  Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
       "2  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
       "3  Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
       "4                               La Guerre Des Tuques   \n",
       "\n",
       "                                         description   productid     imageid  \\\n",
       "0                                                NaN  3804725264  1263597046   \n",
       "1                                                NaN   436067568  1008141237   \n",
       "2  PILOT STYLE Touch Pen de marque Speedlink est ...   201115110   938777978   \n",
       "3                                                NaN    50418756   457047496   \n",
       "4  Luc a des id&eacute;es de grandeur. Il veut or...   278535884  1077757786   \n",
       "\n",
       "                                           tokens2id  \n",
       "0  [3, 2, 6, 4, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [19, 14, 9, 8, 28, 20, 25, 8, 10, 21, 18, 12, ...  \n",
       "2  [33, 38, 31, 30, 32, 34, 39, 36, 35, 37, 0, 0,...  \n",
       "3  [45, 42, 43, 40, 44, 41, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [46, 14, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17b3f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train / Test / Valid (60 / 20 / 20)\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(all_data, target_le, test_size=0.2, random_state = 0, stratify = target_le) \n",
    "X_train_raw, X_valid_raw, y_train, y_valid = train_test_split(X_train_raw, y_train, test_size=0.2, random_state = 0, stratify = y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bbf445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille totale du jeu reduit : 84916 entrées\n",
      "Train : 54345 \n",
      "Validation : 13587 \n",
      "Test : 16984\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille totale du jeu reduit : {} entrées\".format(len(all_data)))\n",
    "print(\"Train : {} \\nValidation : {} \\nTest : {}\".format(len(X_train_raw),len(X_valid_raw),len( X_test_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a4f0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../data/images/image_train/\"\n",
    "\n",
    "# liste des chemins vers les images\n",
    "X_train_path = [images_dir + \"image_\" + str(X_train_raw.iloc[k,3]) + \"_product_\"+str(X_train_raw.iloc[k,2])+\".jpg\" for k in range(len(X_train_raw))]\n",
    "X_valid_path = [images_dir + \"image_\" + str(X_valid_raw.iloc[k,3]) + \"_product_\"+str(X_valid_raw.iloc[k,2])+\".jpg\" for k in range(len(X_valid_raw))]\n",
    "X_test_path = [images_dir + \"image_\" + str(X_test_raw.iloc[k,3]) + \"_product_\"+str(X_test_raw.iloc[k,2])+\".jpg\" for k in range(len(X_test_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7d48a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_size = 299 # Modèle Xception\n",
    "batch_size = 32\n",
    "prefetch_factor = tf.data.experimental.AUTOTUNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b396c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction pour le chargement des images sans augmentation\n",
    "def load_image(filepath) :\n",
    "    # Chargement de l'image du df en mémoire\n",
    "    im = tf.io.read_file(filepath)\n",
    "    \n",
    "    # Décodage de l'info dans un tenseur RGB\n",
    "    im = tf.image.decode_jpeg(im, 3)\n",
    "    \n",
    "    # Retourne l'image à la bonne dimension \n",
    "    im = tf.image.resize(im, size=(image_size, image_size))\n",
    "    \n",
    "    # Preprocess du modèle\n",
    "    im = tf.keras.applications.xception.preprocess_input(im)\n",
    "        \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3196178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 09:40:55.807111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fonction pour le chargement des images AVEC augmentation\n",
    "\n",
    "import random\n",
    "# Génerateur aléatoire\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "# fonction pour le chargement des images\n",
    "def load_transform_image(filepath) :\n",
    "    # Chargement de l'image du df en mémoire\n",
    "    im = tf.io.read_file(filepath)\n",
    "    \n",
    "    # Décodage de l'info dans un tenseur RGB\n",
    "    im = tf.image.decode_jpeg(im, 3)\n",
    "    \n",
    "    # Data Augmentation : ajustement aléatoire du contraste\n",
    "    contrast_factor = random.random() + 1.0\n",
    "    im = tf.image.adjust_contrast(im,contrast_factor = contrast_factor)\n",
    "    \n",
    "    # Data Augmentation : retournement horizontal aléatoire\n",
    "    im = tf.image.stateless_random_flip_left_right(im,rng.make_seeds(2)[0])\n",
    "   \n",
    "    # Retourne l'image à la bonne dimension \n",
    "    im = tf.image.resize(im, size=(image_size, image_size))\n",
    "    \n",
    "    # Preprocess du modèle\n",
    "    im = tf.keras.applications.xception.preprocess_input(im)\n",
    "        \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ceb667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données pour la validation au cours de l'entrainement\n",
    "# définition du dataset\n",
    "dataset_valid = tf.data.Dataset.from_tensor_slices((X_valid_path, y_valid))\n",
    "\n",
    "# application de la fonction load_image au dataset\n",
    "dataset_valid = dataset_valid.map(lambda y, z : [load_image(y),z], num_parallel_calls = -1).cache()\n",
    "\n",
    "# regroupement en batchs\n",
    "dataset_valid = dataset_valid.batch(batch_size).prefetch(prefetch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10fc43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données de test après l'entrainement\n",
    "# définition du dataset\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test_path, y_test))\n",
    "\n",
    "# application de la fonction load_image au dataset\n",
    "dataset_test = dataset_test.map(lambda y, z : [load_image(y),z], num_parallel_calls = -1).cache()\n",
    "\n",
    "# regroupement en batchs\n",
    "dataset_test = dataset_test.batch(batch_size).prefetch(prefetch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df287303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des données d'entrainement\n",
    "# définition du dataset\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
    "\n",
    "# application de la fonction load_image au dataset\n",
    "dataset_train = dataset_train.map(lambda y, z : [(load_transform_image(y)),z], num_parallel_calls = -1).cache()\n",
    "\n",
    "# regroupement en batchs\n",
    "dataset_train = dataset_train.shuffle(1000).batch(batch_size).prefetch(prefetch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97738100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle Xception \n",
    "xception = Xception(weights='imagenet', \n",
    "                    include_top= False,\n",
    "                    input_shape = (image_size,image_size,3)) \n",
    "\n",
    "for layer in xception.layers[:105]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in xception.layers[105:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0477cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de classes en sortie\n",
    "n_class = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376deb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 10, 10, 2048)      20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27)                55323     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,916,803\n",
      "Trainable params: 8,457,683\n",
      "Non-trainable params: 12,459,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Modèle 1 : 1 simple classifieur\n",
    "model = Sequential()\n",
    "model.add(xception)\n",
    "model.add(GlobalAveragePooling2D()) \n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a8e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc4a7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "# Instanciation du callback \n",
    "checkpoint = callbacks.ModelCheckpoint(filepath = \"../data/checkpoint_xception_dataset_full\",\n",
    "                                       monitor = 'val_loss',\n",
    "                                       save_best_only = True,\n",
    "                                       save_weights_only = True,\n",
    "                                       mode = 'min',\n",
    "                                       save_freq = 'epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42f99a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1699/1699 [==============================] - 12609s 7s/step - loss: 1.4545 - accuracy: 0.5695 - val_loss: 1.2220 - val_accuracy: 0.6323\n",
      "Epoch 2/4\n",
      "1699/1699 [==============================] - 12601s 7s/step - loss: 1.0758 - accuracy: 0.6685 - val_loss: 1.3006 - val_accuracy: 0.6155\n",
      "Epoch 3/4\n",
      "1699/1699 [==============================] - 12813s 8s/step - loss: 0.8116 - accuracy: 0.7407 - val_loss: 1.4778 - val_accuracy: 0.6100\n",
      "Epoch 4/4\n",
      "1699/1699 [==============================] - 12967s 8s/step - loss: 0.5819 - accuracy: 0.8084 - val_loss: 1.5392 - val_accuracy: 0.6176\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset_train,\n",
    "                    epochs = 4,\n",
    "                    validation_data = dataset_valid, \n",
    "                    callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da9f733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/xception_unfreeze105_4ep_dataset_full_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model, \"../models/xception_unfreeze105_4ep_dataset_full_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce89001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération de l'accuray pour les 3 modèles\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e87bc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c301e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de performances des 3 modèles pendant l'apprentissage\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Xception unfreeze / 10 epochs\")\n",
    "plt.plot(epochs,acc, \"--\", label = \"Training \" )\n",
    "plt.plot(epochs,val_acc,label = \"Validation\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Xception unfreeze / 10 epochs\")\n",
    "plt.plot(epochs,loss, \"--\", label = \"Training \" )\n",
    "plt.plot(epochs,val_loss,label = \"Validation\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c3d59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_model = load(\"../models/xception_unfreeze105_4ep_dataset_full_data.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1beb7efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 2127s 4s/step - loss: 1.5547 - accuracy: 0.6201\n",
      "Accuracy - Modèle Xception Full Data : 0.6200541853904724\n"
     ]
    }
   ],
   "source": [
    "score = reload_model.evaluate(dataset_test)\n",
    "\n",
    "print(\"Accuracy - Modèle Xception Full Data :\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94632d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
